## PROJECT K23A Εργασία 3
	Χίου Ρίτα Άννα sdi1700192
	Χουσιανίτη Κατερίνα sdi1700194
	Μπούρα Τατιάνα sdi1700100

## Αρχεία και οργάνωση
Χωρίσαμε τα παραδοτέα τις εργασίας σε Project1, Project3, Project3 φακέλους και τα datasets συνεχίζουν να βρίσκονται σε δικό τους φάκελο(datasets). Να σημειωθεί ότι οι δύο φάκελοι Project1 , Project3, Project3 δεν περοέχουν ίδιο κώδικα.  Μέσα στον φάκελο Project3 θα βρείτε την main.c, το makefile και το παρόν README.md καθώς και φακέλους οργανωμένους θεματικά είτε ανά δομή (π.χ. hash_table,list) είτε ανά ενότητα (π.χ. classification). 

## Compile and run
Για να τρέξει κατευθείαν από το repository στο Project3, χρησιμοποιώντας τα αρχεία στο φάκελο dataset υπάρχουν 2(δύο) τρόποι,

***1***
> make -C Project3

> ./Project3/prog ./datasets/camera_specs/2013_camera_specs ./datasets/sigmod_large_labelled_dataset.csv ./Project2/common-english-words.txt

					ή
> ./Project3/prog ./datasets/camera_specs/2013_camera_specs ./datasets/sigmod_medium_labelled_dataset.csv ./Project2/common-english-words.txt
  
***2***
> cd Project3

> make  

> ./prog ../datasets/camera_specs/2013_camera_specs/ ../datasets/sigmod_large_labelled_dataset.csv ../Project2/common-english-words.txt

					ή  					
> ./prog ../datasets/camera_specs/2013_camera_specs/ ../datasets/sigmod_medium_labelled_dataset.csv ../Project2/common-english-words.txt,

  
όπου sigmod_large_labelled_dataset.csv είναι το datasetW και το sigmod_medium_labelled_dataset το datasetY.  
  
Για το unit testing κάνουμε
> make tests  

όπου θα προκύψουν 6 εκτελέσιμα: 
- για τη δομή list
- για τη δομη hash_table όπου αποθηκεύονται όλες οι πληροφορίες κάθε .json αρχείου
- για τη δομη hash_table_pair που χρησιμοποιείται για τη δημιουργία των x_array, y_array για το training
- για τις δομές του vocabulary (hashTableVOC και λίστα)
- για τις συναρτήσεις που αφορούν τον υπολογισμό των tfidf, bag of words και τον επαναπροσδιορισμό του vocabulary
- για τη δομή wordInfo που χρησιμοποιείται για την αποθήκευση του περιεχομένου (λέξεων/αριθμού εμφανίσεων) του κάθε .json αρχείου
Για τα επιμέρους arguments του κάθε εκτελέσιμου ανατρέξατε στο TEST_LIST του κάθε .c του testing.

## Λειτουργικότητα / Σχεδιαστικές επιλογές

**Generic/Sorted List**
Οι generic λίστες μας φάνηκαν χρήσιμες για τις ανάγκες των εργασιών 1 και 2 καθώς αξιοποιούνται με ποικίλους τρόπους (για τη δημιουργία κλικών από spec_ids, την διαχείριση του collision στα hashtable, για την συλλογή λέξεων (vocabulary) και την αποθήκευση των μη-κλικών) πάντα διατηρώντας την εισαγωγή from front συμπεριφορά για αποτελεσματικότερη εισαγωγή, την δυνατότητα ταξινόμησης κλπ. 
Για τις επιπλεόν απαιτήσεις της τρίτης εργασίας υλοποιήθηκαν οι κατάλληλες συναρτήσεις έτσι ώστε η λίστα να μπορεί να λειτουργεί και ως ουρά (Queue) για την αποθήκευση των εργασιών που καλούνται να εκτελέσουν τα νήματα. Συγκεκριμένα, μπορεί να εφαρμοστεί η εισαγωγή στοιχείων με τη λογική append end καθώς και η αφαίρεση στοιχείου από την κεφαλή της λίστας (pop).

**Unit Testing**
Εφαρμόζουμε unit testing στις συναρτήσεις που υλοποιήθηκαν στις λίστες για τη χρήση τους ως ουρά (queue), τα τρία είδη hashTable, το wordInfo structure,  και στις κύριες συναρτήσεις για τη δημιουργία των απαραίτητων για το training δομών καθώς επίσης τις βασικές συναρτήσεις για τη διαχείριση των νημάτων (threads). Οι μόνες συναρτήσεις που δεν ελέγχονται από το testing είναι μερικές από τις εκείνες που ασχολούνται με το input-output του προγράμματος, αυτές που αποδεσμεύουν μνήμη(αν και το πρόγραμμα δεν έχει κανένα leak ή error σύμφωνα με το Valgrind) και κάποιες μικρές συναρτήσεις εντός των δομών που ελέγχονται έμμεσα, αφού αποτελούν τμήμα μεγαλύτερων συναρτήσεων που ελέγχονται κανονικά. 
Επιπλέον για την εφαρμογή unit testing στις συναρτήσεις του job_scheduler, υλοποιήθηκαν απλοποιημένες οι αντίστοιχες συναρτήσεις για τον έλεγχο του συγχρονισμού των νημάτων (threads) σύμφωνα με την οργάνωση του κανονικού εκτελέσιμου. 

**Εισαγωγή Πολυνηματισμού**
Στο παρόν εκτελέσιμο η διαδικασία εκπαίδευσης του μοντέλου εφαρμόζεται αξιοποιώντας τις δυνατότητες που προσφέρει ο πολυνηματισμός(παραλληλία), επιτυγχάνοντας με αυτόν τον τρόπο αποδοτικότερη υπολογιστικά εκπαίδευση. Πιο συγκεκριμένα, σε κάθε στάδιο της επαναληπτικής εκπαιδευτικής διαδικασίας δημιουργούνται νήματα τα οποία αναλαμβάνουν την Batch Gradient Descent με batch μεγέθους 1024. 
>Διαδικασία
Στην συνάρτηση gradient_descent() σε κάθε επανάληψη δημιουργείται ο καθορισμένος αριθμός νημάτων (100) και το training set χωρίζεται σε batches τα οποία εισάγονται με την μορφή εργασιών (Job) σε μια ουρά υλοποιημένη με τη generic λίστα. Στη συνέχεια τα νήματα συγχρονίζονται κατάλληλα, με χρήση mutexes και conditions, έτσι ώστε να αναλάβουν την εκτέλεση εργασιών από τη λίστα. Αξίζει να σημειωθεί πως με το που εμφανιστεί job στην ουρά κάποιο νήμα αναλαμβάνει τη διεκπεραίωσή του και έτσι είναι αρκετά αποδοτικό χρονικά.Τέλος, κάθε νήμα εναποθέτει τα αποτελέσματα που υπολόγισε σε μια λίστα από την οποία τα αποτελέσματα αρθροίζονται κατάλληλα και γίνεται update των βαρών. Το κάθε νήμα εν τέλει απελευθερώνει όλη τη μνήμη.

**Επανεκπαίδευση Μοντέλου (retraining)**
Στο παρόν εκτελέσιμο η διαδικασία της επανεκπαίδευσης του μοντέλου γίνεται επαναληπτικά και ξεκινάει από ένα βασικό training set (το 60% του συνόλου των παρατηρήσεων που έχει επιλεχθεί τυχαία) και threshold = 0.1. Στο υπόλοιπο 40% των παρατηρήσεων (που αντιστοιχεί 20% και 20% στα validation set και test set αντίστοιχα) έχουμε πρόσβαση μέσω δεικτών, από ένα επιπλέον set το not_yet_trained και έχει υλοποιηθεί ένας στατικός πίνακας τύπου boolean που αρχικοποιείται σε 'false' και υποδεικνύει για κάθε παρατήρηση αν ανήκει ή όχι στο τρέχων training set. Σχετικά με τον πίνακα boolean που αναφέρθηκε προηγουμένως αξίζει να αναφέρουμε συγκεκριμένα πως αξιοποιείται για την αποφυγή εκ νέου εισαγωγής της ίδιας παρατήρησης στο training set, καθώς γίνεται έλεγχος της αντίστοιχης τιμής του πίνακα. 
>Διαδικασία
Σε κάθε επανάληψη υπολογίζεται από το μοντέλο η πιθανότητα πρόβλεψης, για την κατάταξη σε κλίκες και αντικλίκες, των παρατηρήσεων που δεν ανήκουν στο αρχικό training set. Βάση των πιθανοτήτων αυτών γίνεται κατάλληλος έλεγχος σύμφωνα με το τρέχον threshold και επιλέγονται οι παρατηρήσεις για τις οποίες το μοντέλο μπορεί πιο 'σίγουρα' να αποδώσει label 0 ή 1. Οι παρατηρήσεις αυτές προσθέτονται στο αρχικό training set, η αντίστοιχη θέση του boolean πίνακα γίνεται 'true' καθώς και το threshold αυξάνεται κατά 0.1. Προκειμένου να μην δημιουργηθούν διπλότυπα των παρατηρήσεων στη μνήμη, επαναδεσμεύεται μνήμη  για το training set, για την αποθήκευση δεικτών στις παρατηρήσεις αυτές, με χρήση realloc(). 

























 
